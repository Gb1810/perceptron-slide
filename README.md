
# Perceptron ‚Äì Atividade Pr√°tica (IA)

üìå Aluno: Guilherme Barroso dos Santos  
üìå RA: 125111401820  
üìå Curso: Engenharia de Software  
üìå Professor: Alexandre ‚ÄúMontanha‚Äù de Oliveira  
üìå Data de entrega: 07/09/2025  

---

Este reposit√≥rio cont√©m um exemplo simples de Perceptron em Python e as respostas √†s perguntas solicitadas pelo professor.  
O c√≥digo est√° em `main.py` e o README inclui uma explica√ß√£o did√°tica sobre o modelo e sobre o processo de treinamento.

> Observa√ß√£o: o c√≥digo fornecido como base n√£o implementa *treinamento*; ele demonstra as fun√ß√µes de entrada (`perceptron_input`) e de sa√≠da (`perceptron_output`) e um `main` para execu√ß√£o.  
> As respostas sobre treinamento descrevem o procedimento geral de um Perceptron para fins pedag√≥gicos.

---

## Como executar
1. Tenha o Python 3 instalado.
2. Rode:
   ```bash
   python main.py




# Perceptron ‚Äì Atividade Pr√°tica (IA)

Este reposit√≥rio cont√©m um exemplo simples de Perceptron em Python e as respostas √†s perguntas solicitadas pelo professor. O c√≥digo est√° em `main.py` e o README inclui uma explica√ß√£o did√°tica sobre o modelo e sobre o processo de treinamento.

> Observa√ß√£o: o c√≥digo fornecido como base n√£o implementa *treinamento*; ele demonstra as fun√ß√µes de entrada (`perceptron_input`) e de sa√≠da (`perceptron_output`) e um `main` para execu√ß√£o. As respostas sobre treinamento descrevem o procedimento geral de um Perceptron para fins pedag√≥gicos.

## Como executar
1. Tenha o Python 3 instalado.
2. Rode:
   ```bash
   python main.py
   ```

---

## Perguntas respondidas

### 1) Conceito
O Perceptron √© um neur√¥nio artificial que calcula uma soma ponderada das entradas, adiciona um **vi√©s** (*bias*) e aplica uma fun√ß√£o de ativa√ß√£o do tipo degrau para gerar sa√≠das bin√°rias (0 ou 1). Historicamente, ele foi um dos primeiros modelos de redes neurais (final dos anos 1950), abrindo caminho para o estudo de aprendizado de m√°quina ao mostrar que uma m√°quina pode **aprender** ajustando pesos a partir de dados. Embora simples, serviu de base para arquiteturas modernas mais profundas.

### 2) Funcionamento (classificador linear) e limita√ß√µes
Dizer que o Perceptron √© um **classificador linear** significa que ele procura um hiperplano (uma linha no 2D, um plano no 3D, etc.) que **separa** as classes no espa√ßo de atributos. Se os dados forem **linearmente separ√°veis**, o Perceptron consegue encontrar um conjunto de pesos que classifica corretamente os exemplos.
  
**Limita√ß√µes principais:**
- N√£o resolve problemas **n√£o linearmente separ√°veis** (ex.: padr√£o XOR) sem engenharia de atributos ou camadas extras.
- Pode ser sens√≠vel √† **escala** dos atributos e √† escolha da **taxa de aprendizado**.
- Modela apenas **fronteiras de decis√£o lineares**; rela√ß√µes complexas exigem modelos mais expressivos (p.ex., redes multicamadas).

### 3) C√≥digo: etapas do treinamento (conceito geral)
O arquivo `main.py` desta base n√£o cont√©m um la√ßo de treinamento; ele mostra apenas fun√ß√µes de c√°lculo e um `main` para impress√£o de resultados. Em um *treinamento* t√≠pico de Perceptron, as etapas seriam:
1. **Inicializar** pesos e vi√©s (geralmente pequenos valores, aleat√≥rios ou zeros).
2. Para cada amostra (entrada `x`, r√≥tulo `y`):
   - **Predizer**: \( \hat{y} = \text{step}(w \cdot x + b) \).
   - **Calcular o erro**: \( e = y - \hat{y} \).
   - **Atualizar** pesos e vi√©s (regra do Perceptron):  
     \( w \leftarrow w + \eta \cdot e \cdot x \) e \( b \leftarrow b + \eta \cdot e \), onde \(\eta\) √© a taxa de aprendizado.
3. **Iterar** sobre o conjunto de dados por algumas √©pocas at√© convergir (ou atingir um crit√©rio de parada).

No c√≥digo base, voc√™ encontrar√°:
- `perceptron_input(...)`: soma ponderada + bias.
- `perceptron_output(...)`: aplica o limiar (degrau) para obter 0/1.
- `main()`: apenas demonstra a chamada das fun√ß√µes.

### 4) Aplica√ß√£o pr√°tica (exemplo)
Um exemplo simples: **detec√ß√£o de spam** com poucas caracter√≠sticas bin√°rias (ex.: presen√ßa de certas palavras-chave). Se existir uma combina√ß√£o linear dessas caracter√≠sticas que separa razoavelmente ‚Äúspam‚Äù de ‚Äún√£o spam‚Äù, o Perceptron pode funcionar bem, com baixo custo computacional e f√°cil implementa√ß√£o. Em contextos mais complexos, modelos n√£o lineares seriam prefer√≠veis.

---

## Estrutura do projeto
```
perceptron-slide/
‚îú‚îÄ main.py
‚îú‚îÄ README.md
‚îú‚îÄ LICENSE
‚îî‚îÄ .gitignore
```

## Licen√ßa
MIT. Veja o arquivo `LICENSE`.

---

*Gerado em 08/09/2025.*
